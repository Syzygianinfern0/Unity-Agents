{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Navigation \n",
    "## Installing Unity\n",
    "You can use [Installation Instructions](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md)\n",
    "from the ML Agents repo to get started.\n",
    "\n",
    "##### This Banana Environment works only on API version 4 of Unity... So install mlagents version 4 or downgrade using ```pip install mlagents==0.4```\n",
    "\n",
    "$Note$ : This works only with Python 3.6 for now so you can go ahead and run ```conda create -n <env_name> python=3.6```\n",
    "and set up TensorFlow in it. Also you need to edit the *setup.py* files from the ML Agents repo to fix compatibility \n",
    "issues. You can refer to [my edited repo](https://github.com/Syzygianinfern0/ml-agents) to understand if you didn't.\n",
    "\n",
    "Let's get started!!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "INFO:unityagents:\n'Academy' started successfully!\nUnity Academy name: Academy\n        Number of Brains: 1\n        Number of External Brains : 1\n        Lesson number : 0\n        Reset Parameters :\n\t\t\nUnity brain name: BananaBrain\n        Number of Visual Observations (per agent): 0\n        Vector Observation space type: continuous\n        Vector Observation space size (per agent): 37\n        Number of stacked Vector Observation: 1\n        Vector Action space type: discrete\n        Vector Action space size (per agent): 4\n        Vector Action descriptions: , , , \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "unity_env = UnityEnvironment('Banana_Windows_x86_64/Banana.exe')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Understanding Unity\n",
    "Environments contain brains which are responsible for deciding the actions of their associated agents. Here we check \n",
    "for the first brain available, and set it as the default brain we will be controlling from Python."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "brain_name = unity_env.brain_names[0]\n",
    "brain = unity_env.brains[brain_name]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Number of agents: 1\nNumber of actions: 4\nStates look like: [1.         0.         0.         0.         0.84408134 0.\n 0.         1.         0.         0.0748472  0.         1.\n 0.         0.         0.25755    1.         0.         0.\n 0.         0.74177343 0.         1.         0.         0.\n 0.25854847 0.         0.         1.         0.         0.09355672\n 0.         1.         0.         0.         0.31969345 0.\n 0.        ]\nStates have length: 37\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = unity_env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Agent\n",
    "Now that we have understood our aliases from OpenAi Gym in Unity, all we need to do is port our codes from OpenAI to \n",
    "Unity and they will work perfectly fine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Score: 0.0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "env_info = unity_env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = unity_env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "unity_env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lets Begin!\n",
    "I plan to use a Double DQN for this environment. Maybe in the next try, I will add a Dueling DQN to a policy based\n",
    "approach. I have created the model in the assets class as we will not be doing the basic stuff again."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 24)                912       \n_________________________________________________________________\ndense_1 (Dense)              (None, 4)                 100       \n=================================================================\nTotal params: 1,012\nTrainable params: 1,012\nNon-trainable params: 0\n_________________________________________________________________\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_2 (Dense)              (None, 24)                912       \n_________________________________________________________________\ndense_3 (Dense)              (None, 4)                 100       \n=================================================================\nTotal params: 1,012\nTrainable params: 1,012\nNon-trainable params: 0\n_________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from assets.models.dqn import DQN\n",
    "agent = DQN(action_space=action_size,\n",
    "            observation_space=state_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training\n",
    "How will our first shot at training in Unity work? I hope it does well.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}